{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV file (data.csv) as a DataFrame\n",
    "ufc_df = pd.read_csv(\"Resources/data.csv\")\n",
    "ufc_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial columns\n",
    "ufc_df = ufc_df.drop(\n",
    "    columns=[\n",
    "        \"BPrev\",\n",
    "        \"RPrev\",\n",
    "        \"BStreak\",\n",
    "        \"B_Location\",\n",
    "        \"R_Location\",\n",
    "        \"Event_ID\",\n",
    "        \"Fight_ID\",\n",
    "        \"B_ID\",\n",
    "        \"R_ID\",\n",
    "        \"B_HomeTown\",\n",
    "        \"R_HomeTown\",\n",
    "        \"Date\",\n",
    "    ]\n",
    ")\n",
    "ufc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only wins and losses (i.e., Red & Blue)\n",
    "\n",
    "# Display `value_counts()` on `winner` column before modification\n",
    "print(\"Before\", \"-\" * 20, ufc_df.winner.value_counts(), \"-\" * 20, \"\\n\", sep=os.linesep)\n",
    "\n",
    "ufc_df = ufc_df.loc[(ufc_df.winner == \"blue\") | (ufc_df.winner == \"red\")]\n",
    "\n",
    "# Display results\n",
    "print(\"After\", \"-\" * 20, ufc_df.winner.value_counts(), \"-\" * 20, sep=os.linesep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Imputation transformer for completing missing values.\n",
    "# Standardize features by removing the mean and scaling to unit variance with `StandardScalar()`.\n",
    "numeric_transformer = Pipeline(\n",
    "    # steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"object\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"object\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", LogisticRegression(max_iter=500)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = ufc_df.drop(\"winner\", axis=1)\n",
    "y = ufc_df[\"winner\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Diagram of Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression without Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split features and target arrays\n",
    "\n",
    "# Binary encoding\n",
    "dummies_df = pd.get_dummies(ufc_df)\n",
    "X = dummies_df.drop(columns=[\"winner_blue\", \"winner_red\"])\n",
    "X = X.fillna(0)\n",
    "\n",
    "y = ufc_df[\"winner\"]\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Logistic Regression Model\n",
    "clf = LogisticRegression(solver=\"lbfgs\", max_iter=200)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict Outcomes\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Regression with Subset of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Max_round\", \"B_Age\", \"B_Height\", \"B_Weight\", \"R_Age\", \"R_Height\", \"B_Weight\"]\n",
    "categorical_features = [\"winby\"]\n",
    "target_value = [\"winner\"]\n",
    "\n",
    "subset_features = numeric_features + categorical_features + target_value\n",
    "\n",
    "# Select subset of features\n",
    "ufc_subset_df = ufc_df[subset_features]\n",
    "\n",
    "# Drop null (?)\n",
    "# ufc_subset_df = ufc_subset_df.dropna(how=\"any\", axis=\"rows\")\n",
    "\n",
    "# Reset index\n",
    "ufc_subset_df = ufc_subset_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding\n",
    "dummies_df = pd.get_dummies(ufc_subset_df)\n",
    "X = dummies_df.drop(columns=[\"winner_blue\", \"winner_red\"])\n",
    "X = X.fillna(0)\n",
    "\n",
    "y = ufc_subset_df[\"winner\"]\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Logistic Regression Model\n",
    "clf = LogisticRegression(solver=\"lbfgs\", max_iter=200)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict Outcomes\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Print accuracy score\n",
    "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: StandardScaler on get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Should StandScalar() be applied to non-numerical categories that got encoded? (Ex. OneHotEncoder() or get_dummies()) \n",
    "\n",
    "# We know that there are 4 columns that are going to be encoded with get_dummies() since they are `object` dtype\n",
    "# `columns=` -> Column names in the DataFrame to be encoded. If columns is None then all the columns with object or category dtype will be converted.\n",
    "display(ufc_df.dtypes.value_counts())\n",
    "\n",
    "# Should `dummy_na=True`? -> Add a column to indicate NaNs, if False NaNs are ignored.\n",
    "display(ufc_df.select_dtypes(include=\"object\").isnull().sum())\n",
    "\n",
    "\n",
    "# We are encoding the object variables into uint8\n",
    "dummies_df = pd.get_dummies(ufc_df)\n",
    "display(dummies_df.dtypes.value_counts())\n",
    "\n",
    "# Should StandScalar() be applied to non-numerical categories that got encoded? (Ex. OneHotEncoder() or get_dummies()) \n",
    "# dummies_df.select_dtypes(include=\"uint8\").columns.tolist()\n",
    "# dummies_df.select_dtypes(exclude=\"uint8\").columns.tolist()\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d13ba43a92555a83a91537475403bd0fdb075d2524ba3a00b200fd1cb72e7c9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
